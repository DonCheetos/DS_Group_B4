{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_count": 1,
   "id": "705e05ac-b189-4d39-a4bf-fa95e22e1f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7af4cee-c612-4608-a98c-eeebf465006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables:        name\n",
      "0  metadata\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Category</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Language</th>\n",
       "      <th>Status</th>\n",
       "      <th>Published</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Packaged</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Chapters</th>\n",
       "      <th>Words</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Story URL</th>\n",
       "      <th>Author URL</th>\n",
       "      <th>Summary</th>\n",
       "      <th>word_count</th>\n",
       "      <th>chapter_count</th>\n",
       "      <th>story_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...</td>\n",
       "      <td>The Distant Strains of Triumph</td>\n",
       "      <td>SpartanDelta2</td>\n",
       "      <td>Halo, Mass Effect</td>\n",
       "      <td>Drama, Sci-Fi</td>\n",
       "      <td>English</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2013-07-15</td>\n",
       "      <td>2013-07-15</td>\n",
       "      <td>2013-10-28 09:08:08</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1,180</td>\n",
       "      <td>www.fanfiction.net</td>\n",
       "      <td>http://www.fanfiction.net/s/9493934/1/</td>\n",
       "      <td>http://www.fanfiction.net/u/2727455/SpartanDelta2</td>\n",
       "      <td>A project for my class, a challenge from my te...</td>\n",
       "      <td>1180</td>\n",
       "      <td>1</td>\n",
       "      <td>9493934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...</td>\n",
       "      <td>Mass Effect: Beyond</td>\n",
       "      <td>Cunningham-Hughes</td>\n",
       "      <td>Halo, Mass Effect</td>\n",
       "      <td>Adventure, Sci-Fi</td>\n",
       "      <td>English</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2013-07-21 09:44:53</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>9,971</td>\n",
       "      <td>www.fanfiction.net</td>\n",
       "      <td>http://www.fanfiction.net/s/8573953/1/</td>\n",
       "      <td>http://www.fanfiction.net/u/4262625/Cunningham...</td>\n",
       "      <td>A hardcore Mass Effect fan's retelling of the ...</td>\n",
       "      <td>9971</td>\n",
       "      <td>1</td>\n",
       "      <td>8573953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...</td>\n",
       "      <td>Chaos Infinitium</td>\n",
       "      <td>Sysero of Cain</td>\n",
       "      <td>Halo, Mass Effect</td>\n",
       "      <td>Adventure, Sci-Fi</td>\n",
       "      <td>English</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2011-03-11</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>2014-11-23 22:48:57</td>\n",
       "      <td>T</td>\n",
       "      <td>5</td>\n",
       "      <td>19,447</td>\n",
       "      <td>www.fanfiction.net</td>\n",
       "      <td>https://www.fanfiction.net/s/6816070/1/</td>\n",
       "      <td>https://www.fanfiction.net/u/2362265/Sysero-of...</td>\n",
       "      <td>First Contact never seems to go well. But thin...</td>\n",
       "      <td>19447</td>\n",
       "      <td>5</td>\n",
       "      <td>6816070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...</td>\n",
       "      <td>Tools of Defiance</td>\n",
       "      <td>Magisking</td>\n",
       "      <td>Halo, Mass Effect</td>\n",
       "      <td>Angst, Tragedy</td>\n",
       "      <td>English</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2013-12-22</td>\n",
       "      <td>2013-12-22</td>\n",
       "      <td>2014-02-07 23:48:12</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>997</td>\n",
       "      <td>www.fanfiction.net</td>\n",
       "      <td>https://www.fanfiction.net/s/9946669/1/</td>\n",
       "      <td>https://www.fanfiction.net/u/5244687/Magisking</td>\n",
       "      <td>A One-shot that takes place in the Defiance un...</td>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "      <td>9946669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...</td>\n",
       "      <td>Mass Effect New Origins V2</td>\n",
       "      <td>erttheking</td>\n",
       "      <td>Halo, Mass Effect</td>\n",
       "      <td>Romance, Sci-Fi</td>\n",
       "      <td>English</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2010-10-05</td>\n",
       "      <td>2012-06-09</td>\n",
       "      <td>2014-05-25 15:31:13</td>\n",
       "      <td>T</td>\n",
       "      <td>109</td>\n",
       "      <td>442,687</td>\n",
       "      <td>www.fanfiction.net</td>\n",
       "      <td>https://www.fanfiction.net/s/6376514/1/</td>\n",
       "      <td>https://www.fanfiction.net/u/1835782/erttheking</td>\n",
       "      <td>On the dawn of the 27th century, the UNSC disc...</td>\n",
       "      <td>442687</td>\n",
       "      <td>109</td>\n",
       "      <td>6376514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  \\\n",
       "0  Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...   \n",
       "1  Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...   \n",
       "2  Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...   \n",
       "3  Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...   \n",
       "4  Fanfiction/Halo_ Mass Effect/Completed/Halo_ M...   \n",
       "\n",
       "                            Title             Author           Category  \\\n",
       "0  The Distant Strains of Triumph      SpartanDelta2  Halo, Mass Effect   \n",
       "1             Mass Effect: Beyond  Cunningham-Hughes  Halo, Mass Effect   \n",
       "2                Chaos Infinitium     Sysero of Cain  Halo, Mass Effect   \n",
       "3               Tools of Defiance          Magisking  Halo, Mass Effect   \n",
       "4      Mass Effect New Origins V2         erttheking  Halo, Mass Effect   \n",
       "\n",
       "               Genre Language     Status   Published     Updated  \\\n",
       "0      Drama, Sci-Fi  English  Completed  2013-07-15  2013-07-15   \n",
       "1  Adventure, Sci-Fi  English  Completed  2012-10-01  2012-10-01   \n",
       "2  Adventure, Sci-Fi  English  Completed  2011-03-11  2011-11-17   \n",
       "3     Angst, Tragedy  English  Completed  2013-12-22  2013-12-22   \n",
       "4    Romance, Sci-Fi  English  Completed  2010-10-05  2012-06-09   \n",
       "\n",
       "              Packaged Rating Chapters    Words           Publisher  \\\n",
       "0  2013-10-28 09:08:08      M        1    1,180  www.fanfiction.net   \n",
       "1  2013-07-21 09:44:53      T        1    9,971  www.fanfiction.net   \n",
       "2  2014-11-23 22:48:57      T        5   19,447  www.fanfiction.net   \n",
       "3  2014-02-07 23:48:12      T        1      997  www.fanfiction.net   \n",
       "4  2014-05-25 15:31:13      T      109  442,687  www.fanfiction.net   \n",
       "\n",
       "                                 Story URL  \\\n",
       "0   http://www.fanfiction.net/s/9493934/1/   \n",
       "1   http://www.fanfiction.net/s/8573953/1/   \n",
       "2  https://www.fanfiction.net/s/6816070/1/   \n",
       "3  https://www.fanfiction.net/s/9946669/1/   \n",
       "4  https://www.fanfiction.net/s/6376514/1/   \n",
       "\n",
       "                                          Author URL  \\\n",
       "0  http://www.fanfiction.net/u/2727455/SpartanDelta2   \n",
       "1  http://www.fanfiction.net/u/4262625/Cunningham...   \n",
       "2  https://www.fanfiction.net/u/2362265/Sysero-of...   \n",
       "3     https://www.fanfiction.net/u/5244687/Magisking   \n",
       "4    https://www.fanfiction.net/u/1835782/erttheking   \n",
       "\n",
       "                                             Summary word_count chapter_count  \\\n",
       "0  A project for my class, a challenge from my te...       1180             1   \n",
       "1  A hardcore Mass Effect fan's retelling of the ...       9971             1   \n",
       "2  First Contact never seems to go well. But thin...      19447             5   \n",
       "3  A One-shot that takes place in the Defiance un...        997             1   \n",
       "4  On the dawn of the 27th century, the UNSC disc...     442687           109   \n",
       "\n",
       "  story_id  \n",
       "0  9493934  \n",
       "1  8573953  \n",
       "2  6816070  \n",
       "3  9946669  \n",
       "4  6376514  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the SQLite database (since it's in the same folder, you can just use the filename)\n",
    "db_path = 'metadata-110mil.sqlite'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Check available tables in the database (optional)\n",
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "print(\"Available tables:\", tables)\n",
    "\n",
    "# Specify the table you want to load\n",
    "table_name = 'metadata'  # Replace with your actual table name\n",
    "\n",
    "# Load the table into a DataFrame\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {table_name};\", conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82eec0c-686e-44e6-ad6d-1bd8a7b297c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.iloc[0]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb74d1d-2c77-4540-b71a-ff8be16003aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set the font to a universal one like Noto Sans\n",
    "#rcParams['font.sans-serif'] = ['Noto Sans', 'DejaVu Sans', 'Arial Unicode MS']  # Ensure Noto Sans is installed\n",
    "#rcParams['axes.unicode_minus'] = False  # Avoid issues with minus signs\n",
    "\n",
    "# Load your data (assuming it's already in a DataFrame `df`)\n",
    "# df = pd.read_csv('your_file.csv')  # Uncomment this if you're loading from a CSV file\n",
    "\n",
    "# Split categories by commas and stack them to get a single column of all categories\n",
    "#all_categories = df['Category'].str.split(',').explode()\n",
    "\n",
    "# Strip any extra whitespace from each category (important if there are spaces after commas)\n",
    "#all_categories = all_categories.str.strip()\n",
    "\n",
    "# Count occurrences of each unique category\n",
    "#category_counts = all_categories.value_counts()\n",
    "\n",
    "# Filter categories to include only those with at least 500 occurrences\n",
    "#filtered_category_counts = category_counts[category_counts >= 10000]\n",
    "\n",
    "# Plot as a bar chart\n",
    "#plt.figure(figsize=(20, 6))\n",
    "#filtered_category_counts.plot(kind='bar', color='skyblue')\n",
    "#plt.title('Distribution of Categories (at least 10000 entries)')\n",
    "#plt.xlabel('Category')\n",
    "#plt.ylabel('Count')\n",
    "#plt.xticks(rotation=90, ha='right')\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf1a21-4d70-4507-a199-b889e58acaed",
   "metadata": {},
   "source": [
    "![category_distribution](category_distribution.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7897ab0c-2cc2-4dca-a185-af9906d05f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Take a random sample of 100,000 rows (adjust the number as needed for performance)\n",
    "#sample_df = df['word_count'].sample(100000, random_state=42)\n",
    "\n",
    "#plt.figure(figsize=(10, 6))\n",
    "#sns.histplot(sample_df, bins=50, kde=True)\n",
    "\n",
    "#plt.xlabel(\"Word Count\")\n",
    "#plt.ylabel(\"Frequency\")\n",
    "#plt.title(\"Distribution of Word Count (Sampled)\")\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cbce96-bdb5-428c-9006-22a004697755",
   "metadata": {},
   "source": [
    "![word distribution](word_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a3bee-5f6f-42ae-87eb-5748c03fa81c",
   "metadata": {},
   "source": [
    "<h2> Cleaning and Formating Data: </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fd4d501-9a02-4e6d-b7c7-c6f366c720b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ff692b-9520-4f26-baa2-cda33fa708b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_all_values = df[df[\"Publisher\"] == \"\"].value_counts()#.index.tolist()\n",
    "len(missing_all_values) # TODO: Clean all that are missing. 79 missing is rows that dont hae any value beside path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0c8443e-0960-42fe-a28a-d911ea5cfadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path             0\n",
       "Title            0\n",
       "Author           0\n",
       "Category         0\n",
       "Genre            0\n",
       "Language         0\n",
       "Status           0\n",
       "Published        0\n",
       "Updated          0\n",
       "Packaged         0\n",
       "Rating           0\n",
       "Chapters         0\n",
       "Words            0\n",
       "Publisher        0\n",
       "Story URL        0\n",
       "Author URL       0\n",
       "Summary          0\n",
       "word_count       0\n",
       "chapter_count    0\n",
       "story_id         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_null = (df.isnull()).sum()\n",
    "rows_with_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0e9f10-86f4-4b65-a1e6-eb9bf5357afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652658"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_values = (df.isnull() | (df == \"\")).any(axis=1).sum()\n",
    "rows_with_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f220c411-5a44-4f87-ae7d-078a30c071f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.734885904180304"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_values / len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb18db40-7a06-466c-bf7a-2a130df9d59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path                  0\n",
       "Title               142\n",
       "Author               83\n",
       "Category            120\n",
       "Genre            652471\n",
       "Language             79\n",
       "Status               79\n",
       "Published            81\n",
       "Updated              81\n",
       "Packaged             81\n",
       "Rating               79\n",
       "Chapters             79\n",
       "Words                79\n",
       "Publisher            79\n",
       "Story URL            79\n",
       "Author URL           79\n",
       "Summary             210\n",
       "word_count           79\n",
       "chapter_count        79\n",
       "story_id             79\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_missing = (df == \"\").sum()\n",
    "all_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "152dfa95-31cc-43f1-a527-0f1ca7dfa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing data type for chapter and word count into int type\n",
    "\n",
    "df['word_count'] = pd.to_numeric(df['word_count'], errors='coerce').astype('Int64')\n",
    "df['chapter_count'] = pd.to_numeric(df['chapter_count'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b0cef3-4dfa-48d8-ba62-40331a3540f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_usable = df.copy(deep=True) \n",
    "\n",
    "# Remove redundant  and unimportant columns\n",
    "\n",
    "df_usable = df.drop(columns=['Chapters', 'Words','Path','Story URL','Author URL'])\n",
    "\n",
    "# remove rows where all values are missing (79 of those)\n",
    "\n",
    "df_usable = df_usable[df_usable['word_count'] != '']\n",
    "\n",
    "# All where summary, genre and category is missing\n",
    "\n",
    "df_usable = df_usable[df_usable['Summary'] != '']\n",
    "df_usable = df_usable[df_usable['Category'] != '']\n",
    "df_usable = df_usable[df_usable['Genre'] != '']\n",
    "\n",
    "# Removing extreme word count values  (100 < x < 2,000,000)\n",
    "\n",
    "df_usable = df_usable[(df_usable['word_count'] > 100) & (df_usable['word_count'] < 2000000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79eb11a1-f044-41d5-95b8-90388fdd6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usable = df_usable.drop(columns=['Packaged', 'Publisher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614ab5ed-4645-45cc-a836-aba048e34fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usable = df_usable.drop(columns=['Status', 'Published', 'Updated', 'Rating', 'story_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaa78f6a-7072-42b4-b868-d4ec6c9dce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usable=df_usable[(df_usable['Language'] == 'English')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c99ac13b-fcc3-45da-a325-e80901f55576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usable = df_usable.drop(columns=['Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e0cd115-7975-4f0f-8e0d-d0c9635c8159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4599826"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = df_usable[\"Category\"].value_counts()\n",
    "\n",
    "# Find categories with more than 1000 occurrences\n",
    "categories_to_keep = category_counts[category_counts > 1000].index\n",
    "\n",
    "# Filter the DataFrame\n",
    "df_usable = df_usable[df_usable[\"Category\"].isin(categories_to_keep)]\n",
    "\n",
    "len(df_usable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79c0c06a-59d6-451f-85d3-38c2eea4b68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title            27\n",
       "Author            2\n",
       "Category          0\n",
       "Genre             0\n",
       "Summary           0\n",
       "word_count        0\n",
       "chapter_count     0\n",
       "dtype: Int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting after cleaning all the missing\n",
    "missing = (df_usable == \"\").sum()\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f998fc4d-8994-457e-ab7d-ed9821a92614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Author', 'Category', 'Genre', 'Summary', 'word_count',\n",
       "       'chapter_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b8508e1-9796-4981-913c-7bb31ff42e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4599826"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_usable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cae97e2-f0a9-4f0b-8337-e633f7691664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Ensure nltk resources are downloaded\n",
    "import nltk\n",
    "nltk.download('punkt')  # Tokenizer data\n",
    "nltk.download('wordnet')  # Lemmatizer data\n",
    "nltk.download('stopwords')  # Stopwords data\n",
    "nltk.download('omw-1.4')  # WordNet data\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36c4ece2-7d87-4508-bba6-3763416b36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "custom_stop_words = set(stopwords.words('english')).union(ENGLISH_STOP_WORDS)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabet characters\n",
    "    text = text.lower()  # Lowercase text\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in custom_stop_words]  # Lemmatize and remove stopwords\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to Title and Summary\n",
    "df_usable['processed_title'] = df_usable['Title'].apply(preprocess_text)\n",
    "df_usable['processed_summary'] = df_usable['Summary'].apply(preprocess_text)\n",
    "\n",
    "# Combine title and summary\n",
    "df_usable['combined_text'] = df_usable['processed_title'] + df_usable['processed_summary']\n",
    "\n",
    "# Group by Category and Genre\n",
    "grouped_data = df_usable.groupby(['Category', 'Genre'])\n",
    "\n",
    "# Collect unique words for each group\n",
    "unique_words_by_group = defaultdict(list)\n",
    "\n",
    "for (category, genre), group in grouped_data:\n",
    "    all_words = [word for text in group['combined_text'] for word in text]\n",
    "    unique_words = set(all_words)  # Find unique words\n",
    "    unique_words_by_group[(category, genre)] = unique_words\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "unique_words_df = pd.DataFrame([\n",
    "    {'Category': k[0], 'Genre': k[1], 'Unique_Words': list(v)} \n",
    "    for k, v in unique_words_by_group.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9155f86-39db-4172-b9fd-84c381230dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Unique_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.hack/SIGN</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>[angel, follows, try, salvation, played, reeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.hack/SIGN</td>\n",
       "      <td>Adventure, Angst</td>\n",
       "      <td>[chap, admit, real, deadly, fall, second, abus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.hack/SIGN</td>\n",
       "      <td>Adventure, Drama</td>\n",
       "      <td>[angel, question, follows, try, including, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.hack/SIGN</td>\n",
       "      <td>Adventure, Family</td>\n",
       "      <td>[edited, finished, preinfection, real, centric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.hack/SIGN</td>\n",
       "      <td>Adventure, Fantasy</td>\n",
       "      <td>[angel, try, warp, finished, series, alongside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69989</th>\n",
       "      <td>xxxHOLiC</td>\n",
       "      <td>Supernatural</td>\n",
       "      <td>[stalk, question, ramshackle, wish, karma, wak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69990</th>\n",
       "      <td>xxxHOLiC</td>\n",
       "      <td>Supernatural, Suspense</td>\n",
       "      <td>[decide, affect, watanuki, dragged, coulda, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69991</th>\n",
       "      <td>xxxHOLiC</td>\n",
       "      <td>Supernatural, Tragedy</td>\n",
       "      <td>[love, open, want, wish, happy, nayuki, witch,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69992</th>\n",
       "      <td>xxxHOLiC</td>\n",
       "      <td>Suspense</td>\n",
       "      <td>[unusual, tendency, lead, line, little, realit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69993</th>\n",
       "      <td>xxxHOLiC</td>\n",
       "      <td>Tragedy</td>\n",
       "      <td>[drum, solo, watanuki, daynot, matter, birthda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69994 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                   Genre  \\\n",
       "0      .hack/SIGN               Adventure   \n",
       "1      .hack/SIGN        Adventure, Angst   \n",
       "2      .hack/SIGN        Adventure, Drama   \n",
       "3      .hack/SIGN       Adventure, Family   \n",
       "4      .hack/SIGN      Adventure, Fantasy   \n",
       "...           ...                     ...   \n",
       "69989    xxxHOLiC            Supernatural   \n",
       "69990    xxxHOLiC  Supernatural, Suspense   \n",
       "69991    xxxHOLiC   Supernatural, Tragedy   \n",
       "69992    xxxHOLiC                Suspense   \n",
       "69993    xxxHOLiC                 Tragedy   \n",
       "\n",
       "                                            Unique_Words  \n",
       "0      [angel, follows, try, salvation, played, reeni...  \n",
       "1      [chap, admit, real, deadly, fall, second, abus...  \n",
       "2      [angel, question, follows, try, including, fin...  \n",
       "3      [edited, finished, preinfection, real, centric...  \n",
       "4      [angel, try, warp, finished, series, alongside...  \n",
       "...                                                  ...  \n",
       "69989  [stalk, question, ramshackle, wish, karma, wak...  \n",
       "69990  [decide, affect, watanuki, dragged, coulda, li...  \n",
       "69991  [love, open, want, wish, happy, nayuki, witch,...  \n",
       "69992  [unusual, tendency, lead, line, little, realit...  \n",
       "69993  [drum, solo, watanuki, daynot, matter, birthda...  \n",
       "\n",
       "[69994 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b679ca18-c59e-44c6-982c-803a4d136875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Unique_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36275</th>\n",
       "      <td>Marching Band</td>\n",
       "      <td>Angst, Mystery</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Category           Genre Unique_Words\n",
       "36275  Marching Band  Angst, Mystery           []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_df[unique_words_df[\"Unique_Words\"].apply(len) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b1a84dc-eaed-413f-91a4-73ef6ae611bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully written to filtered_usable_df.csv\n"
     ]
    }
   ],
   "source": [
    "df_usable.shape\n",
    "# Specify the output file\n",
    "output_file = \"filtered_usable_df.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "df_usable.to_csv(output_file, sep=\";\", encoding=\"utf-8\", index=False)  # Set index=False to avoid saving the index\n",
    "\n",
    "print(f\"DataFrame successfully written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8af4f6b2-bb11-4f54-9fca-6845104ea63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4599826"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_usable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b63ec8e5-4f22-431b-9f7a-9efe5237709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully written to unique_words_df.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = \"unique_words_df.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "unique_words_df.to_csv(output_file, sep=\";\", encoding=\"utf-8\", index=False)  # Set index=False to avoid saving the index\n",
    "\n",
    "print(f\"DataFrame successfully written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a5c6764-0b7e-425e-afa4-0331694a603d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4599826"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_usable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993f31f-e29d-447e-b2d6-2115897e1c12",
   "metadata": {},
   "source": [
    "<h2> Build a model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a0c59-8abc-42ea-b268-6135e0b06d9e",
   "metadata": {},
   "outputs": [],
   "outputs": [],
   "source": [
    "df_usable2 = pd.read_csv(\"filtered_usable_df.csv\", sep=\";\")\n",
    "print(df_usable2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec761f86-5b5d-4ad6-a30a-90a320ac3f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usable[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbdec4a-b3d6-4ffe-b15f-bf991149b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usable[\"word_count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1b90f-ae00-4cad-a51e-a2ca268406fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df[['word_count', 'chapter_count']].copy()\n",
    "\n",
    "# Convert these columns to numeric (if needed)\n",
    "numerical_columns = numerical_columns.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop any rows with NaN values in numerical columns to avoid calculation issues\n",
    "numerical_columns = numerical_columns.dropna()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numerical_columns.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.matshow(correlation_matrix, cmap='coolwarm', fignum=1)\n",
    "plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=90)\n",
    "plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation Matrix\", pad=20)\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
